{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 5: Gender Inference - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used for training purposes: https://www.kaggle.com/crowdflower/twitter-user-gender-classification\n",
    "20051 tweets with the description, user, location and text data but also additional fields significantly **gender** and **gender confidence**. These fields had been populated via contributors who were asked to simply view a Twitter profile and judge whether the user was a male, a female, or a brand (non-individual).\n",
    "\n",
    "Code to create machine learning classification algorithms: Dibaka Saha's https://www.kaggle.com/evilport/classify-gender-with-description-and-text \n",
    "\n",
    "We train this program on the forementioned kaggle dataset, and then run it against our own dataset, checking its accuracy in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(top_words, text):\n",
    "    feature = {}\n",
    "    for word in top_words:\n",
    "        feature[word] = word in text.lower()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/05/2013 01:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/01/2012 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>06/11/2009 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>815719231</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:47</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03/11/2010 18:14</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/656336865...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ive seen people on the train with lamps, chair...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20036</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>New York Gritty</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>815719232</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:57</td>\n",
       "      <td>brand</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/24/08 13:03</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/528547133...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@BpackEngineer Thank you for your patience whi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13354</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>815719233</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:48</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/03/2012 21:54</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/508875440...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Gala Bingo clubs bought for å£241m: The UK's l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112117</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>815719234</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:52</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>09/08/2015 04:50</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/658670112...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@_Aphmau_ the pic defines all mcd fangirls/fan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>482</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>815719235</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:49</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5/13/11 3:32</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/513327289...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>@Evielady just how lovely is the tree this yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26085</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.590000e+17</td>\n",
       "      <td>Nottingham, England.</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "5  815719231    False   finalized                   3     10/27/15 1:47   \n",
       "6  815719232    False   finalized                   3     10/27/15 1:57   \n",
       "7  815719233    False   finalized                   3    10/26/15 23:48   \n",
       "8  815719234    False   finalized                   3     10/27/15 1:52   \n",
       "9  815719235    False   finalized                   3     10/27/15 1:49   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "5  female             1.0000        yes                    1.0   \n",
       "6   brand             1.0000        yes                    1.0   \n",
       "7    male             1.0000        yes                    1.0   \n",
       "8  female             1.0000        yes                    1.0   \n",
       "9  female             1.0000        yes                    1.0   \n",
       "\n",
       "            created             ...              \\\n",
       "0  12/05/2013 01:48             ...               \n",
       "1  10/01/2012 13:51             ...               \n",
       "2    11/28/14 11:30             ...               \n",
       "3  06/11/2009 22:39             ...               \n",
       "4     4/16/14 13:23             ...               \n",
       "5  03/11/2010 18:14             ...               \n",
       "6     4/24/08 13:03             ...               \n",
       "7  12/03/2012 21:54             ...               \n",
       "8  09/08/2015 04:50             ...               \n",
       "9      5/13/11 3:32             ...               \n",
       "\n",
       "                                        profileimage  retweet_count  \\\n",
       "0  https://pbs.twimg.com/profile_images/414342229...              0   \n",
       "1  https://pbs.twimg.com/profile_images/539604221...              0   \n",
       "2  https://pbs.twimg.com/profile_images/657330418...              1   \n",
       "3  https://pbs.twimg.com/profile_images/259703936...              0   \n",
       "4  https://pbs.twimg.com/profile_images/564094871...              0   \n",
       "5  https://pbs.twimg.com/profile_images/656336865...              0   \n",
       "6  https://pbs.twimg.com/profile_images/528547133...              0   \n",
       "7  https://pbs.twimg.com/profile_images/508875440...              0   \n",
       "8  https://pbs.twimg.com/profile_images/658670112...              0   \n",
       "9  https://pbs.twimg.com/profile_images/513327289...              0   \n",
       "\n",
       "  sidebar_color                                               text  \\\n",
       "0        FFFFFF  Robbie E Responds To Critics After Win Against...   \n",
       "1        C0DEED  ÛÏIt felt like they were my friends and I was...   \n",
       "2        C0DEED  i absolutely adore when louis starts the songs...   \n",
       "3        C0DEED  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "4             0  Watching Neighbours on Sky+ catching up with t...   \n",
       "5             0  Ive seen people on the train with lamps, chair...   \n",
       "6             0  @BpackEngineer Thank you for your patience whi...   \n",
       "7        C0DEED  Gala Bingo clubs bought for å£241m: The UK's l...   \n",
       "8             0  @_Aphmau_ the pic defines all mcd fangirls/fan...   \n",
       "9        FFFFFF  @Evielady just how lovely is the tree this yea...   \n",
       "\n",
       "  tweet_coord tweet_count   tweet_created      tweet_id        tweet_location  \\\n",
       "0         NaN      110964  10/26/15 12:40  6.590000e+17       main; @Kan1shk3   \n",
       "1         NaN        7471  10/26/15 12:40  6.590000e+17                   NaN   \n",
       "2         NaN        5617  10/26/15 12:40  6.590000e+17                clcncl   \n",
       "3         NaN        1693  10/26/15 12:40  6.590000e+17         Palo Alto, CA   \n",
       "4         NaN       31462  10/26/15 12:40  6.590000e+17                   NaN   \n",
       "5         NaN       20036  10/26/15 12:40  6.590000e+17       New York Gritty   \n",
       "6         NaN       13354  10/26/15 12:40  6.590000e+17             Worldwide   \n",
       "7         NaN      112117  10/26/15 12:40  6.590000e+17                   NaN   \n",
       "8         NaN         482  10/26/15 12:40  6.590000e+17                   NaN   \n",
       "9         NaN       26085  10/26/15 12:40  6.590000e+17  Nottingham, England.   \n",
       "\n",
       "                user_timezone  \n",
       "0                     Chennai  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2                    Belgrade  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4                         NaN  \n",
       "5  Central Time (US & Canada)  \n",
       "6  Eastern Time (US & Canada)  \n",
       "7                         NaN  \n",
       "8                         NaN  \n",
       "9                   Amsterdam  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('gender-classifier-DFE-791531.csv', encoding = 'latin1')\n",
    "#df = shuffle(shuffle(shuffle(df)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_descriptions = df['description']\n",
    "all_tweets = df['text']\n",
    "all_genders = df['gender']\n",
    "all_gender_confidence = df['gender:confidence']\n",
    "description_tweet_gender = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234140\n",
      "13817\n"
     ]
    }
   ],
   "source": [
    "# Creation of bag of words for the description\n",
    "bag_of_words = []\n",
    "c = 0  # for the index of the row\n",
    "stop = stopwords.words('english')\n",
    "for tweet in all_tweets:\n",
    "    description = all_descriptions[c]\n",
    "    gender = all_genders[c]\n",
    "    gender_confidence = all_gender_confidence[c]\n",
    "    \n",
    "    # Remove the rows which has an empty tweet and description\n",
    "    # Remove the rows with unknown or empty gender\n",
    "    # Remove the rows which have gender:confidence < 80%\n",
    "    if (str(tweet) == 'nan' and str(description) == 'nan') or str(gender) == 'nan' or str(gender) == 'unknown' or float(gender_confidence) < 0.8:\n",
    "        c+=1\n",
    "        continue\n",
    "    \n",
    "    if str(tweet) == 'nan':\n",
    "        tweet = ''\n",
    "    if str(description) == 'nan':\n",
    "        description = ''\n",
    "    \n",
    "    # Removal of punctuations\n",
    "    for punct in string.punctuation:\n",
    "        if punct in tweet:\n",
    "            tweet = tweet.replace(punct, \" \")\n",
    "        if punct in description:\n",
    "            description = description.replace(punct, \" \")\n",
    "            \n",
    "    # Adding the word to the bag except stopwords\n",
    "    for word in tweet.split():\n",
    "        if word.isalpha() and word.lower() not in stop:\n",
    "            bag_of_words.append(word.lower())\n",
    "    for word in description.split():\n",
    "        if word.isalpha() and word.lower() not in stop:\n",
    "            bag_of_words.append(word.lower())\n",
    "    \n",
    "    # Using tweet and description for classification\n",
    "    description_tweet_gender.append((tweet+\" \"+description , gender))\n",
    "    c += 1\n",
    "\n",
    "print(len(bag_of_words))\n",
    "print(len(description_tweet_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['co', 'https', 'get', 'love', 'weather', 'like', 'http', 'one', 'life', 'new']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 4000 words which will act as our features of each sentence\n",
    "bag_of_words = nltk.FreqDist(bag_of_words)\n",
    "top_words = []\n",
    "for word in bag_of_words.most_common(4000):\n",
    "    top_words.append(word[0])\n",
    "\n",
    "top_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature set 13817\n",
      "Length of training set 11053\n",
      "Length of testing set 2764\n"
     ]
    }
   ],
   "source": [
    "# Creating the feature set, training set and the testing set\n",
    "feature_set = [(find_features(top_words, text), gender) for (text, gender) in description_tweet_gender]\n",
    "training_set = feature_set[:int(len(feature_set)*4/5)]\n",
    "testing_set = feature_set[int(len(feature_set)*4/5):]\n",
    "\n",
    "print(\"Length of feature set\", len(feature_set))\n",
    "print(\"Length of training set\", len(training_set))\n",
    "print(\"Length of testing set\", len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier accuracy = 63.06078147612156\n",
      "Most Informative Features\n",
      "                 updates = True            brand : female =    168.2 : 1.0\n",
      "                   dates = True            brand : female =     89.8 : 1.0\n",
      "                 weather = True            brand : female =     74.8 : 1.0\n",
      "                 channel = True            brand : female =     67.2 : 1.0\n",
      "              continuous = True            brand : female =     59.6 : 1.0\n",
      "                  update = True            brand : female =     59.2 : 1.0\n",
      "                  latest = True            brand : female =     34.5 : 1.0\n",
      "               subscribe = True            brand : female =     30.6 : 1.0\n",
      "               promoting = True            brand : female =     30.4 : 1.0\n",
      "                  secure = True            brand : female =     30.4 : 1.0\n",
      "                register = True            brand : female =     29.6 : 1.0\n",
      "                    date = True            brand : female =     28.4 : 1.0\n",
      "            photographer = True             male : brand  =     26.5 : 1.0\n",
      "                 husband = True             male : brand  =     26.5 : 1.0\n",
      "               empowered = True            brand : female =     26.2 : 1.0\n",
      "                 gallons = True            brand : female =     26.2 : 1.0\n",
      "               providing = True            brand : male   =     25.3 : 1.0\n",
      "             financially = True            brand : female =     25.3 : 1.0\n",
      "                  saliva = True            brand : female =     24.4 : 1.0\n",
      "                  proves = True            brand : male   =     23.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a naive bayes classifier\n",
    "NB_classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "accuracy = nltk.classify.accuracy(NB_classifier, testing_set)*100\n",
    "print(\"Naive Bayes Classifier accuracy =\", accuracy)\n",
    "NB_classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier accuracy = 64.616497829233\n"
     ]
    }
   ],
   "source": [
    "# Creating a logistic regression classifier\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "accuracy = nltk.classify.accuracy(LogisticRegression_classifier, testing_set)*100\n",
    "print(\"Logistic Regression classifier accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that on the testing data, the Naive Bayes classifier is 63% accurate, and the Logistic Regression classifier is 65% accurate. \n",
    "\n",
    "We now to run it on our own sample of 100 tweets from our dataset and see if it can achieve similar accuracy levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "# Testing with random user-entered data\n",
    "description = \".\"\n",
    "text = \"\"\n",
    "features = find_features(top_words, description+\" \"+text)\n",
    "print(NB_classifier.classify(features))\n",
    "print(LogisticRegression_classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing with the same 1000 rows of our twitter data as human. Note blank description fields have been removed.\n",
    "tweet_descrandtext = pd.read_excel(\"tweets_sample1000_forML.xlsx\")\n",
    "tweet_descrandtext[\"genderML_NB\"] = \"\"\n",
    "tweet_descrandtext[\"genderML_LR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_descrandtext = tweet_descrandtext.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Write regex pattern to remove all punctuation (note: this ML exploration was carried out before pre-processing had been finished on our original dataset)\n",
    "remove = string.punctuation\n",
    "remove = remove + \"“”‘’\"\n",
    "punct_pattern = r\"[{}]\".format(remove)\n",
    "\n",
    "# Loop through dataset to remove punctuation from description and text fields\n",
    "for i in range(len(tweet_descrandtext)):\n",
    "    tweet_descrandtext.at[i,\"description\"] = re.sub(punct_pattern, \" \", tweet_descrandtext.at[i,\"description\"]) # remove punctuation\n",
    "    tweet_descrandtext.at[i,\"text\"] = re.sub(punct_pattern, \" \", tweet_descrandtext.at[i,\"text\"]) # remove punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      level_0   index                                        description  \\\n",
      "0        305   30582   Don t get mad  get even     John F  Kennedy  ...   \n",
      "1        961  177398                                               Gra    \n",
      "2        351  131345   I find your answer vague and unconvincing    ...   \n",
      "3        106  286077   If your heart is filled with patriotism  ther...   \n",
      "4        176  206944   Seek first the Kingdom    and all things shal...   \n",
      "5        318   23769   Atheist   FreeSpeech   Science   Politics   S...   \n",
      "6        837  126384   BlueDress  HeyBlueDress Aspiring  friendofthepod   \n",
      "7        595  188785   Digital  organizer   underground revolutionar...   \n",
      "8        755  184635   DigitalMarketing  married to  LeighPollack  r...   \n",
      "9        330  280110   EdDStudent    CriminalJusticeAdjunct  Addicte...   \n",
      "10       834  109520   LittleMonster  Debater  Democrat and a Minority    \n",
      "11       171  187080   MAGA ⚜️New Orleans•Destin   Alcohol Drug Ment...   \n",
      "12       185   60916                                         MAGA 🇱🇷🐕🐈🙏   \n",
      "13       104    1664   mediadopedealer A Willy Wonka creation 👀 and ...   \n",
      "14        35  118168   ProGod  ProLife  ProGun  ProCop  BackTheBlue ...   \n",
      "15       748   96464   Resist • Animal rights • Equality for all • F...   \n",
      "16       527   66761   Resistance of the political divide becoming t...   \n",
      "17       636  283441                                          SPNFamily   \n",
      "18       115  145209   TheResistance  nonazis  noafd  resist  TrumpR...   \n",
      "19       741  298053   TheWorldNeedsLove\\n BlackUnity\\n ProudVeteran...   \n",
      "20       573    9160   TMLtalk  40yr Fan \\n RiderPride  jointheregim...   \n",
      "21       633   47015   TRUMP  ClintonFoundation   SETHRICH  MAGA  Lo...   \n",
      "22       957  166498   UWG Alum  Capricorn   moviebuff  metalhead  s...   \n",
      "23       209  176937   Whatever   Sith   Dad   cohost of  HashtagGia...   \n",
      "24       457  132729   Writer   mom   trivia host  Used to tweet wit...   \n",
      "25       260  295947    img  via  interior GG Natl Pk    instagram  ...   \n",
      "26       448  206887   CHIN uh do  means God guides  Proud black  Ni...   \n",
      "27       136   35823                               skeptically sighing    \n",
      "28       278   21066                                      wheeze laugh    \n",
      "29       549   99187    curating at museums is my side hustle  and p...   \n",
      "..       ...     ...                                                ...   \n",
      "874      552  143587  Writer Activist Artist focusing on Women s Iss...   \n",
      "875      600   22088  Writer Audio Editor At NBC News Radio  Produce...   \n",
      "876      225    4033  Writing about life  parenthood  cooking and mo...   \n",
      "877      902  127594                                 WVTHS  15  WSU  19   \n",
      "878      328   22625      yea  faze rain   madeintyo follows me  u mad    \n",
      "879      287   37530  Yelp Black Elite  Agile Family advocate  Socia...   \n",
      "880      189  153705  You have been assigned this mountain to show o...   \n",
      "881      616   96570                             young  gifted   black    \n",
      "882      301  137434  Your future is created by what you do today  n...   \n",
      "883       46  295036  Τελειωοις • The perfect stranger • Hustlers Sp...   \n",
      "884      414   23705                           Калеб Мопин   Journalist   \n",
      "885      866  275398  ‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏‏اللھُـم كما خلقتني عَلى ال...   \n",
      "886      512   32510  🇮🇹 Proud Father and Husband Composer Boston Br...   \n",
      "887      368  206189  🇺🇸  Author   Navy  Vet  Journalist  RT d by Pa...   \n",
      "888      400   71803  🇺🇸   Federalist Party   Liberty   Constitution...   \n",
      "889       41   20068  🇺🇸 As the twin sister of  realdonaldtrump I m ...   \n",
      "890      743   15056  🇺🇸 MAGA 🇺🇸PEACE THROUGH STRENGTH Trump Conserv...   \n",
      "891      634  157770  🇺🇸✝️ THE RIGHTS OF MAN COME NOT FROM THE GENER...   \n",
      "892       68  236993  🌸Family   friends are my HEART  laughter is my...   \n",
      "893      408  278575  🐏Carolina Blue🐏   gay but I have a boyfriend s...   \n",
      "894      211  160171  👪 ProLife🗣️ 1A🔫 2A  MichelleKOrts10 My 10 10 P...   \n",
      "895      999   21228  💀☠️ I love my Country  my husband  ericgearhar...   \n",
      "896      310  198352  📝 politics  nbcnews  also  distance runner  in...   \n",
      "897      725  134788  📻Journalist  NYC  Director  Radio Program  Col...   \n",
      "898        2  211144  🕉 Wife  Mom  runner  bike life               G...   \n",
      "899       11  182363  🕎BATSHEVA🕎JewishQueen🕎 KingDavidsWife🕎KingSolo...   \n",
      "900      720   91591                                                🖤💀🦇   \n",
      "901      498  176161                  🙅🏽⏱•GGG •🦉🦈🦇• New Year  New Daddy   \n",
      "902      504  178082                  🙅🏽⏱•GGG •🦉🦈🦇• New Year  New Daddy   \n",
      "903      192  201301   🤠God Bless y all 🇺🇸 cowgirl patriot pirate  MAGA   \n",
      "\n",
      "                user                                               text  \\\n",
      "0        ColeMadsen6   realDonaldTrump Still pandering  I see  75  o...   \n",
      "1           gdubya90           CLEAN COAL      HA     WhatAnIdiot  SOTU   \n",
      "2        Shawnmeintz  Oh  immigrants are gang members and murderers ...   \n",
      "3       LibertyGirl2  So proud of our  POTUS in this moment   Wonder...   \n",
      "4       lemuriangirl            In God We Trust   SOTU  realDonaldTrump   \n",
      "5            guidoV4  WTF   realDonaldTrump   What don t you underst...   \n",
      "6             JLDubs  Only watching this sh thole Cheeto deliver the...   \n",
      "7        JamiahAdams   SOTU Protect our career civil servants   they...   \n",
      "8        iamdanlevey     There was a war on beautiful clean coal   SOTU   \n",
      "9    DamoineWilliams  Trump says  Make America Great Again for all A...   \n",
      "10          13MX2001  You ve deported more families than criminals \\...   \n",
      "11          _loriLLC                              SOTU DRILL BABY DRILL   \n",
      "12        MAGAMomma1  Great economic news and inspiring personal int...   \n",
      "13        Ashlee_Ray  The whole talk tomorrow will be how well he re...   \n",
      "14    DigitalChick73  He said  doody  \\n\\nYes  I m 12  Deal with it ...   \n",
      "15   PoliticalGroove  Immigration   We must ensure the safety of all...   \n",
      "16      TheDailyLeft  End Sequester and Fund Military he says   Trum...   \n",
      "17    The_JessRhodes   pattonoswalt brings life to anything  includi...   \n",
      "18     badgirl_loony   Beautiful clean coal    SOTU https   t co 9ND...   \n",
      "19   LyfeLessons1978  America doesn t need a speech to tell us the s...   \n",
      "20         citrus713   MarkDice That s absolute proof of pure ignora...   \n",
      "21     cleaner_swamp  just look at those   denying dems   knowing fu...   \n",
      "22    PulledOut2Late  I can t go to a  SOTU     gotta stand up every...   \n",
      "23     LukeWheeler01    Quit clapping into the microphone  homes   SOTU   \n",
      "24     TeeheeOConnor  I find Melania s choice to wear a white pantsu...   \n",
      "25        jackhutton        Cocaine and heroin 4 x s a day     SOTU       \n",
      "26     chinedudiokpa         Kaepernick got his own shout out lol  SOTU   \n",
      "27     NotSara_Sarah  Someone s missing from your sanctions shout ou...   \n",
      "28        WillFBrown   SOTU That s pretty dope  Those crutches were ...   \n",
      "29           iMalRay  Every time Trump mentions the wall  I wonder i...   \n",
      "..               ...                                                ...   \n",
      "874         mgyerman   SOTU\\n Is that really  BernieSanders clapping...   \n",
      "875        KVenezia1  Since  realDonaldTrump began his  SOTU\\n  Alex...   \n",
      "876      jamieloujam  I m sorry  did he just say we should never for...   \n",
      "877      penguin5689  Tell the idiot to stop clapping into the micro...   \n",
      "878   Juan_Sanchez33                                       Patton  SOTU   \n",
      "879    GabrielSkelly  Did trump just call the UN an enemy of the USA...   \n",
      "880         vnessa23  I was low key waiting on a commercial so I cou...   \n",
      "881    Shukriya_Elmi  remember when I used to get excited for the  S...   \n",
      "882          CJBECKR  Paid family leave  So self employed  amp  busi...   \n",
      "883        Kim0Br0wn  It still hasn t settled in America really elec...   \n",
      "884      calebmaupin  Defectors from  DPRK who go to  SouthKorea are...   \n",
      "885  sa____sa_____30  This account is very nice worth the follow up\\...   \n",
      "886     jbjrbruzzese               Using fear of war is appalling  SOTU   \n",
      "887    JerretGardner  Best  SOTU speech ever  Bc the best state of t...   \n",
      "888    michael__1776  Correction   1  MORE than 1 8M  Dreamers  get ...   \n",
      "889   sharonaldtrump  RT WhiteHouse   Otto s wonderful parents  Fred...   \n",
      "890     erskineallin   Gitmo Pelosi\\n SOTU \\n\\nCant wait to NOT list...   \n",
      "891         baumsche   SOTU  StateOfTheUnion  StateofOurUnion GREAT ...   \n",
      "892   shellbelle1022  Democrats aren t happy about Americans having ...   \n",
      "893        ShyLee423  You wanna talk about heroes  Trump  HEATHER HE...   \n",
      "894       DrDaveOrts   President Trump reducing high drug prices top...   \n",
      "895          nalugal  This is  Pompeo       StateOfTheUnion  SOTU  F...   \n",
      "896       DartDClark  listening to the McDonald s worker tell you fo...   \n",
      "897        sherships   Struggling communities  especially immigrant ...   \n",
      "898      Beachgirlqn  Don t firefighters deserve praise after all th...   \n",
      "899    ElianaBenador  We have eliminated more regulations than any A...   \n",
      "900    iconictrash97  I didnt think that i would get this upset over...   \n",
      "901    DebUrTheWorst                         Tonight is leg day    SOTU   \n",
      "902    DebUrTheWorst  Mike Pence looks like he dreams of ways to kil...   \n",
      "903  waltwhiteandblu   And WHY WE STAND FOR THE NATIONAL ANTHEM  got...   \n",
      "\n",
      "    gender_username_human gender_description_human gender_final genderML_NB  \\\n",
      "0                       M                        U            M               \n",
      "1                       U                        U            U               \n",
      "2                       M                        U            M               \n",
      "3                       F                        U            F               \n",
      "4                       F                        U            F               \n",
      "5                       M                        U            M               \n",
      "6                       U                        U            U               \n",
      "7                       M                        U            M               \n",
      "8                       M                        U            M               \n",
      "9                       M                        U            M               \n",
      "10                      U                        U            U               \n",
      "11                      F                        U            F               \n",
      "12                      F                        U            F               \n",
      "13                      F                        U            F               \n",
      "14                      F                        F            F               \n",
      "15                      U                        U            U               \n",
      "16                      U                        U            U               \n",
      "17                      M                        U            M               \n",
      "18                      F                        U            F               \n",
      "19                      U                        U            U               \n",
      "20                      U                        U            U               \n",
      "21                      U                        U            U               \n",
      "22                      U                        U            U               \n",
      "23                      M                        M            M               \n",
      "24                      U                        F            F               \n",
      "25                      M                        U            M               \n",
      "26                      U                        F            F               \n",
      "27                      F                        U            F               \n",
      "28                      M                        U            M               \n",
      "29                      U                        U            U               \n",
      "..                    ...                      ...          ...         ...   \n",
      "874                     U                        F            F               \n",
      "875                     U                        U            U               \n",
      "876                     F                        U            F               \n",
      "877                     U                        U            U               \n",
      "878                     M                        U            M               \n",
      "879                     M                        U            M               \n",
      "880                     F                        U            F               \n",
      "881                     U                        U            U               \n",
      "882                     U                        U            U               \n",
      "883                     F                        M            F               \n",
      "884                     M                        U            M               \n",
      "885                     U                        U            U               \n",
      "886                     U                        M            M               \n",
      "887                     M                        U            M               \n",
      "888                     M                        U            M               \n",
      "889                     F                        F            F               \n",
      "890                     M                        U            M               \n",
      "891                     U                        U            U               \n",
      "892                     F                        U            F               \n",
      "893                     M                        U            M               \n",
      "894                     M                        M            M               \n",
      "895                     U                        F            F               \n",
      "896                     M                        U            M               \n",
      "897                     U                        U            U               \n",
      "898                     F                        F            F               \n",
      "899                     F                        F            F               \n",
      "900                     U                        U            U               \n",
      "901                     U                        M            M               \n",
      "902                     U                        M            M               \n",
      "903                     M                        F            M               \n",
      "\n",
      "    genderML_LR  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "5                \n",
      "6                \n",
      "7                \n",
      "8                \n",
      "9                \n",
      "10               \n",
      "11               \n",
      "12               \n",
      "13               \n",
      "14               \n",
      "15               \n",
      "16               \n",
      "17               \n",
      "18               \n",
      "19               \n",
      "20               \n",
      "21               \n",
      "22               \n",
      "23               \n",
      "24               \n",
      "25               \n",
      "26               \n",
      "27               \n",
      "28               \n",
      "29               \n",
      "..          ...  \n",
      "874              \n",
      "875              \n",
      "876              \n",
      "877              \n",
      "878              \n",
      "879              \n",
      "880              \n",
      "881              \n",
      "882              \n",
      "883              \n",
      "884              \n",
      "885              \n",
      "886              \n",
      "887              \n",
      "888              \n",
      "889              \n",
      "890              \n",
      "891              \n",
      "892              \n",
      "893              \n",
      "894              \n",
      "895              \n",
      "896              \n",
      "897              \n",
      "898              \n",
      "899              \n",
      "900              \n",
      "901              \n",
      "902              \n",
      "903              \n",
      "\n",
      "[904 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(tweet_descrandtext.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through dataset to classify each row with the trained Naive Bayes and Logistic Regression classifiers\n",
    "for i in range(len(tweet_descrandtext)):\n",
    "    description=  tweet_descrandtext.at[i, \"description\"]\n",
    "    text= tweet_descrandtext.at[i, \"text\"]\n",
    "    features = find_features(top_words, description+\" \"+text)\n",
    "    tweet_descrandtext.at[i, \"genderML_NB\"]=(NB_classifier.classify(features))\n",
    "    tweet_descrandtext.at[i, \"genderML_LR\"]=(LogisticRegression_classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "512\n",
      "52.9296875\n",
      "904\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy of naive bayes (NB) classification against human classifications of M or F\n",
    "\n",
    "countTotal = (len(tweet_descrandtext))\n",
    "countOK = 0\n",
    "\n",
    "# Loop through data and compare human classification with NB classifications. Where they match, mark \"OK\".\n",
    "for i in range(len(tweet_descrandtext)):\n",
    "    if ((tweet_descrandtext.at[i, \"gender_final\"] == \"U\")):\n",
    "        countTotal-=1\n",
    "        continue\n",
    "    elif ((tweet_descrandtext.at[i, \"genderML_NB\"] == \"female\") & (tweet_descrandtext.at[i, \"gender_final\"] == \"F\")):\n",
    "        countOK+=1\n",
    "    elif ((tweet_descrandtext.at[i, \"genderML_NB\"] == \"male\") & (tweet_descrandtext.at[i, \"gender_final\"] == \"M\")):\n",
    "        countOK+=1\n",
    "        \n",
    "brandCount=0\n",
    "for i in range(len(tweet_descrandtext)):\n",
    "    if ((tweet_descrandtext.at[i, \"genderML_NB\"] == \"brand\")):\n",
    "        brandCount+=1\n",
    "        \n",
    "print(countOK)  # The number of rows where the human's classification matched the algorithm's\n",
    "print(countTotal)  # The total number of rows the human classified with a gender\n",
    "accuracy = (countOK/countTotal)*100  # The percentage accuracy of the algorithm's classifications (taking the human's classifications to be correct)\n",
    "print(accuracy)\n",
    "print(len(tweet_descrandtext))  # Number of classifications the algorithm made in total\n",
    "print(brandCount)  # Number of classifications the algorithm made as 'brand' (neither male nor female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the following stats:\n",
    "\n",
    "- The Naive Bayes algorithm made 780 M/F classifications total (904-124: the 124 were classified as 'brand'). The human made only M/F 512 classifications.\n",
    "\n",
    "- 52.92% of the algorithms M/F classifications were accurate against the human's M/F classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "512\n",
      "58.3984375\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy of logical regression (LR) classification\n",
    "\n",
    "countTotal2 = (len(tweet_descrandtext))\n",
    "countOK2 = 0\n",
    "\n",
    "# Loop through data and compare human classification with LR classifications. Where they match, mark \"OK\".\n",
    "for i in range(len(tweet_descrandtext)):\n",
    "    if ((tweet_descrandtext.at[i, \"gender_final\"] == \"U\")):\n",
    "        countTotal2-=1\n",
    "        continue\n",
    "    elif ((tweet_descrandtext.at[i, \"genderML_LR\"] == \"female\") & (tweet_descrandtext.at[i, \"gender_final\"] == \"F\")):\n",
    "        countOK2+=1\n",
    "    elif ((tweet_descrandtext.at[i, \"genderML_LR\"] == \"male\") & (tweet_descrandtext.at[i, \"gender_final\"] == \"M\")):\n",
    "        countOK2+=1\n",
    "        \n",
    "print(countOK2)  # The number of rows where the human's classification matched the algorithm's\n",
    "print(countTotal2)  # The total number of rows the human classified with a gender\n",
    "accuracy2 = (countOK2/countTotal2)*100  # The percentage accuracy of the algorithm's classifications (taking the human's classifications to be correct)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that 299/512, or 58%, of the LR classifier's M/F classifications were accurate against the human's M/F classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the tweet subset with the new gender columns\n",
    "writer = pd.ExcelWriter('tweets_with_ML_gender.xlsx')\n",
    "tweet_descrandtext.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
